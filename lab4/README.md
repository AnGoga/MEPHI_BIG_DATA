# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ4: –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

**–¶–µ–ª—å**: –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å —Å—É–º–º–∞—Ä–Ω—ã–π –æ–±—ä–µ–º (`price * quantity`) —Ç–æ—Ä–≥–æ–≤ –ø–æ –∫–∞–∂–¥–æ–º—É –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—É —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º 1 —á–∞—Å, –∏—Å–ø–æ–ª—å–∑—É—è Apache Hadoop MapReduce.

---

## üìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ—à–µ–Ω–∏—è

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    INPUT DATA                            ‚îÇ
‚îÇ  HDFS: /user/hive/warehouse/moex_data.db/trades/        ‚îÇ
‚îÇ  Format: JSON (from Lab 3)                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            Apache Hadoop MapReduce                       ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  Mapper:                                                 ‚îÇ
‚îÇ    1. Parse JSON trade                                   ‚îÇ
‚îÇ    2. Extract hour from tradetime                        ‚îÇ
‚îÇ    3. Calculate volume = price * quantity                ‚îÇ
‚îÇ    4. Emit: (secid|hour_start - hour_end, volume)       ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  Reducer:                                                ‚îÇ
‚îÇ    1. Group by (secid, hour)                             ‚îÇ
‚îÇ    2. Sum all volumes                                    ‚îÇ
‚îÇ    3. Emit: secid|hour_start - hour_end ‚Üí total_volume  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    OUTPUT DATA                           ‚îÇ
‚îÇ  HDFS: /user/hive/warehouse/moex_data.db/               ‚îÇ
‚îÇ        trade_volumes_hourly/                             ‚îÇ
‚îÇ  Format: SBER|2024-01-15 10:00:00 - 11:00:00 ‚Üí 38850.0 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üõ†Ô∏è –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è | –í–µ—Ä—Å–∏—è |
|-----------|-----------|--------|
| **–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –¥–≤–∏–∂–æ–∫** | Apache Hadoop MapReduce | 3.2.1 |
| **–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏** | Apache Hadoop YARN | 3.2.1 |
| **–•—Ä–∞–Ω–∏–ª–∏—â–µ** | Apache HDFS | 3.2.1 (–∏–∑ Lab 3) |
| **–Ø–∑—ã–∫** | Kotlin | 1.9.22 |
| **–°–±–æ—Ä–∫–∞** | Gradle | 8.5 |

---

## üìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
lab4/
‚îú‚îÄ‚îÄ docker-compose.yml              # YARN ResourceManager + NodeManager
‚îú‚îÄ‚îÄ hadoop.env                      # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Hadoop/YARN
‚îú‚îÄ‚îÄ README.md                       # –≠—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îÇ
‚îú‚îÄ‚îÄ mapreduce-job/                  # Kotlin MapReduce –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
‚îÇ   ‚îú‚îÄ‚îÄ build.gradle.kts
‚îÇ   ‚îú‚îÄ‚îÄ settings.gradle.kts
‚îÇ   ‚îú‚îÄ‚îÄ gradlew
‚îÇ   ‚îî‚îÄ‚îÄ src/main/kotlin/
‚îÇ       ‚îî‚îÄ‚îÄ ru/mephi/moex/mapreduce/
‚îÇ           ‚îú‚îÄ‚îÄ TradeVolumeJob.kt           # Main –∫–ª–∞—Å—Å
‚îÇ           ‚îú‚îÄ‚îÄ Trade.kt                    # –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö
‚îÇ           ‚îú‚îÄ‚îÄ mapper/
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ TradeVolumeMapper.kt    # Mapper
‚îÇ           ‚îî‚îÄ‚îÄ reducer/
‚îÇ               ‚îî‚îÄ‚îÄ TradeVolumeReducer.kt   # Reducer
‚îÇ
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ start.sh                    # üöÄ All-in-one: —Å–±–æ—Ä–∫–∞ + YARN + submit
    ‚îú‚îÄ‚îÄ build-job.sh                # –°–±–æ—Ä–∫–∞ JAR
    ‚îú‚îÄ‚îÄ start-yarn.sh               # –ó–∞–ø—É—Å–∫ YARN –∫–ª–∞—Å—Ç–µ—Ä–∞
    ‚îú‚îÄ‚îÄ submit-job.sh               # Submit MapReduce job
    ‚îú‚îÄ‚îÄ view-results.sh             # –ü—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    ‚îî‚îÄ‚îÄ stop-yarn.sh                # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ YARN
```

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

1. **JDK 11 –∏–ª–∏ –≤—ã—à–µ**
2. **Docker –∏ Docker Compose**
3. **Lab 3 –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω–∞** (HDFS + Hive —Å –¥–∞–Ω–Ω—ã–º–∏)

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Hive

–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –≤ Hive –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ:

```bash
# –í docker/lab3
docker exec -it hive-server /opt/hive/bin/beeline -u jdbc:hive2://localhost:10000 -n root \
  -e "USE moex_data; SELECT COUNT(*) FROM trades;"
```

–î–æ–ª–∂–Ω–æ –±—ã—Ç—å > 0 –∑–∞–ø–∏—Å–µ–π.

### –ó–∞–ø—É—Å–∫ Lab 4 (–≤—Å—ë –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!)

```bash
cd lab4
./scripts/start.sh
```

**–°–∫—Ä–∏–ø—Ç `start.sh` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:**
1. ‚úÖ –°–æ–±–∏—Ä–∞–µ—Ç JAR —Ñ–∞–π–ª (Gradle shadowJar)
2. ‚úÖ –ó–∞–ø—É—Å–∫–∞–µ—Ç YARN –∫–ª–∞—Å—Ç–µ—Ä (ResourceManager + NodeManager)
3. ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç MapReduce job –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
4. ‚úÖ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Hive

**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** ~3-5 –º–∏–Ω—É—Ç (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –æ–±—ä–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö)

### –ü—Ä–æ—Å–º–æ—Ç—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```bash
./scripts/view-results.sh
```

–ò–ª–∏ –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ HDFS:

```bash
docker exec hadoop-namenode hadoop fs -cat \
  /user/hive/warehouse/moex_data.db/trade_volumes_hourly/part-* | head -20
```

### –û—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
./scripts/stop-yarn.sh
```

---

## üîç –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç

### 1. Mapper: TradeVolumeMapper

**–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ** (JSON –∏–∑ Hive):
```json
{
  "tradeno": 123456,
  "tradetime": "2024-01-15 10:30:45",
  "secid": "SBER",
  "price": 258.5,
  "quantity": 100,
  "buysell": "B"
}
```

**–õ–æ–≥–∏–∫–∞:**
1. –ü–∞—Ä—Å–∏—Ç JSON –≤ –æ–±—ä–µ–∫—Ç `Trade`
2. –ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∞—Å –∏–∑ `tradetime` (10:30:45 ‚Üí 10:00:00)
3. –í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—ä–µ–º: `volume = price * quantity = 258.5 * 100 = 25850.0`
4. –°–æ–∑–¥–∞–µ—Ç –∫–ª—é—á: `SBER|2024-01-15 10:00:00 - 11:00:00`
5. –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–∞—Ä—É: `(key, volume)`

**–í—ã–≤–æ–¥ Mapper:**
```
SBER|2024-01-15 10:00:00 - 11:00:00 ‚Üí 25850.0
SBER|2024-01-15 10:00:00 - 11:00:00 ‚Üí 13000.0
GAZP|2024-01-15 10:00:00 - 11:00:00 ‚Üí 45000.0
```

### 2. Shuffle/Sort (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

Hadoop –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –∫–ª—é—á–∞–º:

```
SBER|2024-01-15 10:00:00 - 11:00:00 ‚Üí [25850.0, 13000.0, ...]
GAZP|2024-01-15 10:00:00 - 11:00:00 ‚Üí [45000.0, ...]
```

### 3. Reducer: TradeVolumeReducer

**–õ–æ–≥–∏–∫–∞:**
1. –ü–æ–ª—É—á–∞–µ—Ç –∫–ª—é—á –∏ –∏—Ç–µ—Ä–∞—Ç–æ—Ä –∑–Ω–∞—á–µ–Ω–∏–π
2. –°—É–º–º–∏—Ä—É–µ—Ç –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è
3. –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤—ã–≤–æ–¥: `key ‚Üí total_volume`

**–í—ã–≤–æ–¥ Reducer:**
```
SBER|2024-01-15 10:00:00 - 11:00:00 ‚Üí 38850.0
GAZP|2024-01-15 10:00:00 - 11:00:00 ‚Üí 45000.0
```

---

## üìä –§–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

**–õ–æ–∫–∞—Ü–∏—è:** `/user/hive/warehouse/moex_data.db/trade_volumes_hourly/`

**–§–æ—Ä–º–∞—Ç:**
```
SECID|YYYY-MM-DD HH:00:00 - HH:00:00 ‚Üí total_volume
```

**–ü—Ä–∏–º–µ—Ä—ã:**
```
SBER|2024-01-15 09:00:00 - 10:00:00 ‚Üí 1234567.89
SBER|2024-01-15 10:00:00 - 11:00:00 ‚Üí 2345678.90
GAZP|2024-01-15 10:00:00 - 11:00:00 ‚Üí 987654.32
LKOH|2024-01-15 10:00:00 - 11:00:00 ‚Üí 543210.98
```

---

## üåê Web UI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã

| –°–µ—Ä–≤–∏—Å | URL | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|-----|----------|
| **YARN ResourceManager** | http://localhost:8088 | –°—Ç–∞—Ç—É—Å –∫–ª–∞—Å—Ç–µ—Ä–∞, –∑–∞–ø—É—â–µ–Ω–Ω—ã–µ jobs |
| **NodeManager** | http://localhost:8042 | –°—Ç–∞—Ç—É—Å worker –Ω–æ–¥—ã |
| **History Server** | http://localhost:8188 | –ò—Å—Ç–æ—Ä–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö jobs |
| **HDFS NameNode** | http://localhost:9870 | –°—Ç–∞—Ç—É—Å HDFS (–∏–∑ Lab 3) |

---

## üîß –†—É—á–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

### –°–±–æ—Ä–∫–∞ JAR –æ—Ç–¥–µ–ª—å–Ω–æ

```bash
./scripts/build-job.sh
```

JAR –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –≤: `mapreduce-job/build/libs/moex-mapreduce-1.0.0-all.jar`

### –ó–∞–ø—É—Å–∫ YARN –æ—Ç–¥–µ–ª—å–Ω–æ

```bash
./scripts/start-yarn.sh
```

### Submit job –æ—Ç–¥–µ–ª—å–Ω–æ

```bash
./scripts/submit-job.sh
```

### –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤

```bash
# ResourceManager
docker logs -f hadoop-resourcemanager

# NodeManager
docker logs -f hadoop-nodemanager

# History Server
docker logs -f hadoop-historyserver
```

---

## üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –¢–∏–ø–∏—á–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏

- **–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:** 2-5 –º–∏–Ω—É—Ç (–¥–ª—è 50,000 - 200,000 —Å–¥–µ–ª–æ–∫)
- **Mappers:** 2-4 (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
- **Reducers:** 1 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
- **Memory:** 1GB –¥–ª—è Map, 2GB –¥–ª—è Reduce

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**–£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ Reducers:**

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `TradeVolumeJob.kt`:
```kotlin
job.numReduceTasks = 3  // –î–æ–±–∞–≤–∏—Ç—å –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è job
```

**–£–≤–µ–ª–∏—á–∏—Ç—å –ø–∞–º—è—Ç—å:**

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `hadoop.env`:
```env
MAPRED_CONF_mapreduce_map_memory_mb=2048
MAPRED_CONF_mapreduce_reduce_memory_mb=4096
```

---

## ‚ùó Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: "moex-network not found"

**–†–µ—à–µ–Ω–∏–µ:** –ó–∞–ø—É—Å—Ç–∏—Ç–µ Lab 3 –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É:
```bash
cd docker/lab3
./scripts/start.sh
```

### –ü—Ä–æ–±–ª–µ–º–∞: "HDFS NameNode is not running"

**–†–µ—à–µ–Ω–∏–µ:** –ó–∞–ø—É—Å—Ç–∏—Ç–µ HDFS –∏–∑ Lab 3:
```bash
cd docker/lab3
docker-compose up -d namenode datanode
```

### –ü—Ä–æ–±–ª–µ–º–∞: "No such file or directory: /user/hive/warehouse/moex_data.db/trades"

**–†–µ—à–µ–Ω–∏–µ:** –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —Å–æ–±–∏—Ä–∞—é—Ç—Å—è –≤ Hive (Lab 1-3):
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç–µ MOEX Collector
cd moex-collector
./gradlew bootRun

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ NiFi dataflow (Lab 3)
# –û—Ç–∫—Ä–æ–π—Ç–µ http://localhost:8082/nifi
```

### –ü—Ä–æ–±–ª–µ–º–∞: Job failed

**–†–µ—à–µ–Ω–∏–µ:** –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –ª–æ–≥–∏ –≤ YARN UI:
1. –û—Ç–∫—Ä–æ–π—Ç–µ http://localhost:8088
2. –ù–∞–π–¥–∏—Ç–µ –≤–∞—à job
3. –ö–ª–∏–∫–Ω–∏—Ç–µ –Ω–∞ Application ID
4. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –ª–æ–≥–∏ Map/Reduce tasks

### –ü—Ä–æ–±–ª–µ–º–∞: Out of Memory

**–†–µ—à–µ–Ω–∏–µ:** –£–≤–µ–ª–∏—á—å—Ç–µ –ø–∞–º—è—Ç—å –≤ `hadoop.env` (—Å–º. —Ä–∞–∑–¥–µ–ª –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)

---

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

### HDFS

```bash
# –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ output –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
docker exec hadoop-namenode hadoop fs -ls /user/hive/warehouse/moex_data.db/trade_volumes_hourly/

# –ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
docker exec hadoop-namenode hadoop fs -cat /user/hive/warehouse/moex_data.db/trade_volumes_hourly/part-r-00000

# –£–¥–∞–ª–∏—Ç—å output –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
docker exec hadoop-namenode hadoop fs -rm -r /user/hive/warehouse/moex_data.db/trade_volumes_hourly
```

### YARN

```bash
# –°–ø–∏—Å–æ–∫ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
docker exec hadoop-resourcemanager yarn application -list

# –°—Ç–∞—Ç—É—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
docker exec hadoop-resourcemanager yarn application -status <APPLICATION_ID>

# –£–±–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
docker exec hadoop-resourcemanager yarn application -kill <APPLICATION_ID>
```

---

## üéØ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Lab 4:

- ‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –ø–∞–∫–µ—Ç–Ω–æ —Å –ø–æ–º–æ—â—å—é MapReduce
- ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ HDFS
- ‚úÖ –ú–æ–∂–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–æ—á–∞—Å–æ–≤—ã–µ –æ–±—ä–µ–º—ã —Ç–æ—Ä–≥–æ–≤

**–°–ª–µ–¥—É—é—â–∞—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è:** Lab 6 - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (Apache Pinot + Superset)

---

## üìñ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Apache Hadoop MapReduce](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)
- [Apache Hadoop YARN](https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html)
- [Kotlin for Big Data](https://kotlinlang.org/)

---

## üë• –ê–≤—Ç–æ—Ä—ã

–°—Ç—É–¥–µ–Ω—Ç—ã –ú–ò–§–ò, –∫—É—Ä—Å "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö"
