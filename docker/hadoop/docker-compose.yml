services:
  # PostgreSQL - Metastore database for Hive
  postgres-metastore:
    image: postgres:15-alpine
    container_name: hive-metastore-db
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hivepassword
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5433:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - hadoop-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive"]
      interval: 10s
      timeout: 5s
      retries: 5

  # HDFS NameNode
  namenode:
    image: ghcr.io/apache/hadoop:3.4.2-lean
    container_name: hdfs-namenode
    hostname: namenode
    environment:
      - CLUSTER_NAME=moex-hadoop-cluster
      - "CORE-SITE.XML_fs.defaultFS=hdfs://namenode:9000"
      - "CORE-SITE.XML_hadoop.http.staticuser.user=root"
      - "CORE-SITE.XML_hadoop.proxyuser.hue.hosts=*"
      - "CORE-SITE.XML_hadoop.proxyuser.hue.groups=*"
      - "HDFS-SITE.XML_dfs.replication=2"
      - "HDFS-SITE.XML_dfs.permissions.enabled=false"
      - "HDFS-SITE.XML_dfs.webhdfs.enabled=true"
      - "HDFS-SITE.XML_dfs.namenode.rpc-bind-host=0.0.0.0"
      - "HDFS-SITE.XML_dfs.namenode.servicerpc-bind-host=0.0.0.0"
      - "HDFS-SITE.XML_dfs.namenode.http-bind-host=0.0.0.0"
      - "HDFS-SITE.XML_dfs.namenode.https-bind-host=0.0.0.0"
      - "HDFS-SITE.XML_dfs.namenode.datanode.registration.ip-hostname-check=false"
      - "HDFS-SITE.XML_dfs.client.use.datanode.hostname=true"
      - "HDFS-SITE.XML_dfs.datanode.use.datanode.hostname=true"
      - "HDFS-SITE.XML_dfs.namenode.name.dir=file:///opt/hadoop/dfs/name"
    command: ["bash","-lc","test -d /opt/hadoop/dfs/name/current || hdfs namenode -format -nonInteractive; exec hdfs namenode"]
    ports:
      - "9870:9870"  # NameNode Web UI
      - "9000:9000"  # HDFS port
    volumes:
      - ../../data/hadoop/namenode:/opt/hadoop/dfs/name
    networks:
      - hadoop-network
#    command: ["hdfs", "namenode"]
    healthcheck:
      test: ["CMD-SHELL", "hdfs dfsadmin -report || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # HDFS DataNode 1
  datanode1:
    image: ghcr.io/apache/hadoop:3.4.2-lean
    container_name: hdfs-datanode1
    hostname: datanode1
    environment:
      - CLUSTER_NAME=moex-hadoop-cluster
      - "CORE-SITE.XML_fs.defaultFS=hdfs://namenode:9000"
      - "HDFS-SITE.XML_dfs.replication=2"
      - "HDFS-SITE.XML_dfs.permissions.enabled=false"
      - "HDFS-SITE.XML_dfs.webhdfs.enabled=true"
      - "HDFS-SITE.XML_dfs.client.use.datanode.hostname=true"
      - "HDFS-SITE.XML_dfs.datanode.use.datanode.hostname=true"
      - "HDFS-SITE.XML_dfs.datanode.data.dir=file:///opt/hadoop/dfs/data"
    volumes:
      - ../../data/hadoop/datanode1:/opt/hadoop/dfs/data
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy
    command: ["hdfs", "datanode"]

  # HDFS DataNode 2
  datanode2:
    image: ghcr.io/apache/hadoop:3.4.2-lean
    container_name: hdfs-datanode2
    hostname: datanode2
    environment:
      - CLUSTER_NAME=moex-hadoop-cluster
      - "CORE-SITE.XML_fs.defaultFS=hdfs://namenode:9000"
      - "HDFS-SITE.XML_dfs.replication=2"
      - "HDFS-SITE.XML_dfs.permissions.enabled=false"
      - "HDFS-SITE.XML_dfs.webhdfs.enabled=true"
      - "HDFS-SITE.XML_dfs.client.use.datanode.hostname=true"
      - "HDFS-SITE.XML_dfs.datanode.use.datanode.hostname=true"
      - "HDFS-SITE.XML_dfs.datanode.data.dir=file:///opt/hadoop/dfs/data"
    volumes:
      - ../../data/hadoop/datanode2:/opt/hadoop/dfs/data
    networks:
      - hadoop-network
    depends_on:
      namenode:
        condition: service_healthy
    command: ["hdfs", "datanode"]

  # Hive Metastore
  hive-metastore:
    image: apache/hive:4.0.0
    container_name: hive-metastore
    hostname: hive-metastore
    environment:
      SERVICE_NAME: metastore
      DB_DRIVER: postgres
      SERVICE_OPTS: "-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres-metastore:5432/metastore -Djavax.jdo.option.ConnectionUserName=hive -Djavax.jdo.option.ConnectionPassword=hivepassword"
    ports:
      - "9083:9083"  # Metastore Thrift port
    volumes:
      - ./config/hive:/opt/hive/conf
      - ../../data/hive/warehouse:/opt/hive/data/warehouse
      - ./drivers/postgresql-42.7.4.jar:/opt/hive/lib/postgresql-42.7.4.jar:ro

    networks:
      - hadoop-network
    depends_on:
      postgres-metastore:
        condition: service_healthy
      namenode:
        condition: service_healthy
    command: >
      bash -c "
      /opt/hive/bin/schematool -dbType postgres -initSchema || true &&
      /opt/hive/bin/hive --service metastore
      "

  # HiveServer2
  hiveserver2:
    image: apache/hive:4.0.0
    container_name: hiveserver2
    hostname: hiveserver2
    environment:
      SERVICE_NAME: hiveserver2
      SERVICE_OPTS: "-Dhive.metastore.uris=thrift://hive-metastore:9083"
      HADOOP_CLASSPATH: "/opt/tez/*:/opt/tez/lib/*:"
      HADOOP_CLIENT_OPTS: "-Xmx1G"
    ports:
      - "10000:10000"
      - "10002:10002"
    volumes:
      - ./config/hive:/opt/hive/conf:ro
      - ../../data/hive/warehouse:/opt/hive/data/warehouse
      - ./drivers/postgresql-42.7.4.jar:/opt/hive/lib/postgresql-42.7.4.jar:ro
    networks:
      - hadoop-network
    depends_on:
      - hive-metastore
      - namenode
    command: >
      bash -c "
      /opt/hive/bin/hive --service hiveserver2
      "




  # Apache NiFi
  nifi:
    image: apache/nifi:1.25.0
    container_name: apache-nifi
    hostname: nifi
    ports:
      - "8443:8443"   # NiFi HTTPS UI
      - "8082:8080"   # NiFi HTTP UI (mapped to 8082 to avoid conflict with Kafka UI on 8080)
    environment:
      - NIFI_WEB_HTTPS_PORT=8443
      - NIFI_WEB_HTTP_PORT=8080
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=adminadminadmin
      - NIFI_SENSITIVE_PROPS_KEY=nifiPropsKey123456
    volumes:
      - ../../data/nifi/conf:/opt/nifi/nifi-current/conf
      - ../../data/nifi/database:/opt/nifi/nifi-current/database_repository
      - ../../data/nifi/flowfile:/opt/nifi/nifi-current/flowfile_repository
      - ../../data/nifi/content:/opt/nifi/nifi-current/content_repository
      - ../../data/nifi/provenance:/opt/nifi/nifi-current/provenance_repository
      - ../../data/nifi/state:/opt/nifi/nifi-current/state
      - ../../data/nifi/logs:/opt/nifi/nifi-current/logs
      - ./nifi-templates:/opt/nifi/nifi-current/templates
    networks:
      - hadoop-network
    extra_hosts:
      - "host.docker.internal:host-gateway"  # Allow NiFi to access Kafka on host
    healthcheck:
      test: ["CMD-SHELL", "curl -k https://localhost:8443/nifi-api/system-diagnostics || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

volumes:
  postgres-data:
    driver: local

networks:
  hadoop-network:
    driver: bridge
