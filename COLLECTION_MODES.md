# Режимы сбора данных MOEX Collector

## Обзор

MOEX Collector работает в двух режимах для обеспечения полноты и непрерывности сбора данных:

1. **Initial Load** - начальная загрузка всех данных
2. **Incremental Load** - постоянное догоняние новых данных

## Initial Load (Начальная загрузка)

### Когда запускается

- При первом запуске приложения
- После удаления или сброса файла курсора (`data/collection-cursor.json`)
- После явного вызова `cursorService.reset()`

### Как работает

1. Приложение загружает курсор из файла `data/collection-cursor.json`
2. Если `initialLoadComplete = false`, запускается Initial Load
3. Система загружает **ВСЕ** сделки с `lastTradeTime` (по умолчанию - начало текущего дня) до текущего момента
4. Используется автоматическая пагинация - делается столько запросов, сколько нужно для загрузки всех данных
5. Все данные отправляются в Kafka
6. Курсор обновляется на текущее время
7. Флаг `initialLoadComplete` устанавливается в `true`

### Пример

```
Текущее время: 15:30:00
lastTradeTime: 00:00:00 (начало дня)

Initial Load:
  ├─ Запрос 1: from=00:00:00, till=15:30:00, start=0, limit=5000 → 5000 сделок
  ├─ Запрос 2: from=00:00:00, till=15:30:00, start=5000, limit=5000 → 5000 сделок
  ├─ Запрос 3: from=00:00:00, till=15:30:00, start=10000, limit=5000 → 3500 сделок
  └─ Запрос 4: from=00:00:00, till=15:30:00, start=13500, limit=5000 → 0 сделок (конец)

Итого: 13,500 сделок загружено
Курсор обновлен: lastTradeTime = 15:30:00
```

### Характеристики

- **Скорость**: Зависит от количества данных и rate limiting
- **Полнота**: Гарантирует загрузку ВСЕХ сделок с момента старта
- **API запросы**: Много (зависит от объема данных)
- **Запускается**: Только один раз

## Incremental Load (Догоняющая загрузка)

### Когда запускается

- После завершения Initial Load
- Каждые `moex.collector.interval-ms` миллисекунд (по умолчанию 3 секунды)

### Как работает

1. Система загружает `lastTradeTime` из курсора
2. Определяет текущее время как `till`
3. Запрашивает **все** сделки в диапазоне `[lastTradeTime, till]` с автоматической пагинацией
4. Фильтрует дубликаты (на случай перекрытия временных окон)
5. Отправляет новые данные в Kafka
6. Обновляет курсор на `till`

### Пример

```
Цикл 1 (15:30:00):
  lastTradeTime = 15:30:00
  till = 15:30:03 (прошло 3 секунды)

  Запрос: from=15:30:00, till=15:30:03, start=0, limit=5000
  Результат: 127 сделок

  Отправлено в Kafka: 127 сделок
  Курсор обновлен: lastTradeTime = 15:30:03

Цикл 2 (15:30:03):
  lastTradeTime = 15:30:03
  till = 15:30:06

  Запрос: from=15:30:03, till=15:30:06, start=0, limit=5000
  Результат: 89 сделок

  Отправлено в Kafka: 89 сделок
  Курсор обновлен: lastTradeTime = 15:30:06
```

### Обработка больших объемов

Если за 3 секунды произошло >5000 сделок (очень маловероятно на MOEX):

```
Цикл N (пиковая нагрузка):
  from = 15:45:00
  till = 15:45:03

  Запрос 1: start=0, limit=5000 → 5000 сделок
  Запрос 2: start=5000, limit=5000 → 5000 сделок
  Запрос 3: start=10000, limit=5000 → 2300 сделок
  Запрос 4: start=12300, limit=5000 → 0 сделок

  Итого: 12,300 сделок за 3 секунды

  ✅ Все сделки загружены благодаря пагинации!
```

### Характеристики

- **Скорость**: Быстрая (обычно 1 запрос на цикл)
- **Полнота**: Гарантирует 0 пропусков благодаря временным окнам
- **API запросы**: Мало (1-2 запроса на цикл в обычном режиме)
- **Запускается**: Постоянно

## Гарантии полноты данных

### Почему не пропускаются сделки

1. **Временные окна не пересекаются**
   ```
   Цикл 1: [T0, T1]
   Цикл 2: [T1, T2]  ← Начинается с конца предыдущего
   Цикл 3: [T2, T3]
   ```

2. **Автоматическая пагинация**
   - Если данных >5000, делаются дополнительные запросы
   - Snapshot MOEX API фиксирует результат на момент первого запроса

3. **Дедупликация**
   - Даже если окна случайно перекроются, дубликаты отфильтруются по `tradeNo`

4. **Персистентность курсора**
   - Курсор сохраняется на диск после каждого цикла
   - После перезапуска продолжается с того же места

## Конфигурация

### application.yml

```yaml
moex:
  api:
    rate-limit-ms: 1000    # Пауза между запросами (1 сек)
  collector:
    interval-ms: 3000      # Интервал между циклами сбора (3 сек)
    batch-size: 5000       # Размер батча для пагинации
```

### Рекомендации

**Для высокой пропускной способности:**
```yaml
interval-ms: 2000          # Меньше интервал = чаще проверяем
batch-size: 5000           # Максимум для MOEX API
rate-limit-ms: 1000        # Минимум по ТЗ
```

**Для экономии API запросов:**
```yaml
interval-ms: 5000          # Больше интервал = меньше запросов
batch-size: 5000           # Все равно максимум
rate-limit-ms: 1000        # Минимум по ТЗ
```

## Метрики

Система собирает следующие метрики:

- `totalTradesCollected` - всего сделок собрано
- `totalDuplicatesFiltered` - дубликатов отфильтровано
- `totalCyclesCompleted` - циклов завершено
- `totalApiCalls` - API запросов сделано
- `totalErrors` - ошибок произошло
- `avgTradesPerCycle` - среднее сделок за цикл
- `lastCycleDurationMs` - длительность последнего цикла
- `uptimeSeconds` - время работы приложения

Метрики выводятся в лог каждые 60 секунд.

## Файлы данных

### data/collection-cursor.json

```json
{
  "lastTradeTime": "2024-01-15T15:30:03",
  "initialLoadComplete": true,
  "totalTradesCollected": 45230,
  "totalCyclesCompleted": 1520,
  "lastUpdateTime": "2024-01-15T15:30:03"
}
```

**Расположение**: `moex-collector/data/collection-cursor.json`

**Функции:**
- Хранит последнее время обработанных сделок
- Флаг завершения Initial Load
- Статистика сбора данных
- Автоматически создается при первом запуске

### Сброс курсора

Чтобы заново загрузить все данные:

```bash
# Удалить файл курсора
rm moex-collector/data/collection-cursor.json

# Перезапустить приложение
./run-collector.sh
```

Или программно:
```kotlin
cursorService.reset()
```

## Производительность

### Типичные показатели

**Initial Load (9:00 - 18:30 торговая сессия):**
- Время: ~5-10 минут
- Сделок: 50,000 - 200,000
- API запросы: 10 - 40

**Incremental Load:**
- Цикл: 3 секунды
- Сделок за цикл: 50 - 500 (в среднем)
- API запросы: 1 (обычно)

## Troubleshooting

### Проблема: Initial Load не завершается

**Причины:**
- Слишком много данных
- Медленный интернет
- MOEX API недоступен

**Решение:**
```bash
# Посмотреть логи
tail -f logs/application.log

# Проверить метрики
# Должны расти totalApiCalls и totalTradesCollected
```

### Проблема: Пропущены сделки

**Проверка:**
```bash
# Проверить курсор
cat moex-collector/data/collection-cursor.json

# Проверить метрики
# Смотреть на totalErrors
```

**Решение:**
- Если курсор сбился - удалить и перезапустить
- Проверить логи на ошибки API

### Проблема: Слишком много API запросов

**Причина:** Высокая активность рынка + малый interval-ms

**Решение:**
```yaml
# Увеличить интервал
moex:
  collector:
    interval-ms: 5000  # было 3000
```

## Сравнение со старым подходом

| Параметр | Старый подход | Новый подход |
|----------|---------------|--------------|
| Пропуски | Возможны | Невозможны |
| Пагинация | Нет | Автоматическая |
| Курсор | В памяти | На диске |
| Перезапуск | Теряется состояние | Продолжается с того же места |
| Метрики | Нет | Полные |
| Режимы | Один | Два (Initial + Incremental) |
| Временные фильтры | Нет | Есть |
| Дедупликация | Простая | Двойная (по времени + по ID) |

## Примеры использования

### Запуск с нуля

```bash
# 1. Запустить Kafka
./start-kafka.sh

# 2. Запустить collector
./run-collector.sh

# При первом запуске:
# - Выполнится Initial Load (загрузка всех данных с начала дня)
# - Затем переключится на Incremental Load (догоняние)
```

### Перезапуск после остановки

```bash
# Остановить (Ctrl+C)
# Запустить снова
./run-collector.sh

# Initial Load НЕ выполнится (уже завершен)
# Сразу Incremental Load (продолжит с lastTradeTime)
```

### Загрузить данные заново

```bash
# Удалить курсор
rm moex-collector/data/collection-cursor.json

# Запустить
./run-collector.sh

# Initial Load выполнится снова
```
